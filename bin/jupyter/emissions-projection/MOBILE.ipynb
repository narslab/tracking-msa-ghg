{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3080e544-fcb9-4367-ade9-fb9f7fd98ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct, ConstantKernel as C\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared, WhiteKernel, ConstantKernel, DotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fb30ba-24a8-4cd0-866c-adc7703464c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../results/historical_VMT_msa_basedon2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m msa_vmt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../results/historical_VMT_msa_basedon2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \n\u001b[0;32m      2\u001b[0m msa_vmt \u001b[38;5;241m=\u001b[39m msa_vmt\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m msa_vmt \u001b[38;5;241m=\u001b[39m msa_vmt[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../results/historical_VMT_msa_basedon2022.csv'"
     ]
    }
   ],
   "source": [
    "msa_vmt = pd.read_csv('../../../results/historical_VMT_msa_basedon2022.csv',index_col=None) \n",
    "msa_vmt = msa_vmt.set_index('Year')\n",
    "msa_vmt = msa_vmt[::-1]\n",
    "msa_vmt\n",
    "\n",
    "# Define new column names\n",
    "new_column_names = ['New Haven (billion miles)', 'Hartford (billion miles)', 'Bridgeport (billion miles)']\n",
    "\n",
    "# Assign new column names to the DataFrame\n",
    "msa_vmt.columns = new_column_names\n",
    "\n",
    "msa_vmt.index.name = 'year'\n",
    "\n",
    "#msa_vmt.index = pd.to_datetime(msa_vmt.index, format='%Y')\n",
    "msa_vmt.index.freq = 'AS'\n",
    "df=msa_vmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0306a24-4cd9-40c9-a2a2-50eecf5ee473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NHM_data = df['New Haven (billion miles)']\n",
    "y_NHM =NHM_data.values.reshape(-1, 1)\n",
    "x_NHM = NHM_data.index.to_numpy().reshape(-1, 1)\n",
    "\n",
    "x_NHM_df = pd.DataFrame(x_NHM, columns=['Year'])\n",
    "\n",
    "# # Now you can use iloc for indexing\n",
    "# split_index_x = round(len(x_NHM_df) * 0.9)\n",
    "# X_train = x_NHM_df.iloc[:split_index_x].copy()\n",
    "# X_test = x_NHM_df.iloc[split_index_x:].copy()\n",
    "\n",
    "y_NHM_df = pd.DataFrame(y_NHM, columns=['New Haven (billion miles)'])\n",
    "\n",
    "# Now you can use iloc for indexing\n",
    "# split_index_y = round(len(y_NHM_df) * 0.9)\n",
    "# Y_train = y_NHM_df.iloc[:split_index_y].copy()\n",
    "# Y_test = y_NHM_df.iloc[split_index_y:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08d434-32e7-4d6b-b13b-67e8d4ece35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kernels = [\n",
    "    C(3.0) * RBF(length_scale=2.0),\n",
    "    C(3.0) * Matern(length_scale=2.0, nu=1.5)]\n",
    "    #C(3.0) * RationalQuadratic(length_scale=2.0, alpha=0.1),\n",
    "    #C(3.0) * ConstantKernel(constant_value=1.0)]\n",
    "    #C(3.0) * DotProduct(sigma_0=1.0)]\n",
    "    #C(3.0) * ExpSineSquared(length_scale=2.0, periodicity=1.0)]\n",
    "    #C(3.0) * RBF(length_scale=1.0) + WhiteKernel(noise_level=0.1),\n",
    "    #C(3.0) * DotProduct() + C(1.0) * RBF(length_scale=2.0)]\n",
    "\n",
    "# Time series split for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "X = x_NHM\n",
    "y = y_NHM\n",
    "\n",
    "# List to store the best scores and corresponding kernels and parameters\n",
    "results = []\n",
    "\n",
    "# Logarithmically spaced values for length scale and alpha\n",
    "length_scales = np.logspace(-2, 2, 5)\n",
    "alphas = np.logspace(-2, 2, 5)\n",
    "\n",
    "# length_scales = np.array([-0.1,0,1,2,4,10])\n",
    "# alphas = np.array([-0.1,0,1,2,4,10])\n",
    "\n",
    "# Define the mean absolute percentage error function\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "\n",
    "for kernel in kernels:\n",
    "    for length_scale in length_scales:\n",
    "        for alpha in alphas:\n",
    "            try:\n",
    "                # Set the length scale parameter correctly for different kernels\n",
    "                if hasattr(kernel.k2, 'length_scale'):\n",
    "                    kernel.k2.length_scale = length_scale\n",
    "                elif hasattr(kernel.k1, 'length_scale'):\n",
    "                    kernel.k1.length_scale = length_scale\n",
    "                \n",
    "                # Set the alpha parameter if the kernel is RationalQuadratic\n",
    "                if isinstance(kernel.k2, RationalQuadratic):\n",
    "                    kernel.k2.alpha = alpha\n",
    "                elif isinstance(kernel.k1, RationalQuadratic):\n",
    "                    kernel.k1.alpha = alpha\n",
    "\n",
    "                rmse_scores = []\n",
    "                mae_scores = []\n",
    "                mape_scores = []\n",
    "                for train_index, test_index in tscv.split(X):\n",
    "                    X_train, X_test = X[train_index], X[test_index]\n",
    "                    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "                    gp.fit(X_train, y_train)\n",
    "                    y_pred, _ = gp.predict(X_test, return_std=True)\n",
    "                    \n",
    "                    # Compute the metrics\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                    mae = mean_absolute_error(y_test, y_pred)\n",
    "                    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "                    \n",
    "                    rmse_scores.append(rmse)\n",
    "                    mae_scores.append(mae)\n",
    "                    mape_scores.append(mape)\n",
    "                \n",
    "                mean_rmse = np.mean(rmse_scores)\n",
    "                mean_mae = np.mean(mae_scores)\n",
    "                mean_mape = np.mean(mape_scores)\n",
    "                \n",
    "                results.append((mean_rmse, mean_mae, mean_mape, kernel, kernel.get_params()))\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Sort results by the RMSE score\n",
    "results.sort(key=lambda x: x[0])\n",
    "\n",
    "# Print the top 10 results\n",
    "print(\"Top 10 Kernel Configurations:\")\n",
    "for i, (rmse, mae, mape, kernel, params) in enumerate(results[:10]):\n",
    "    print(f\"Rank {i+1}:\")\n",
    "    print(f\"  RMSE: {rmse}\")\n",
    "    print(f\"  MAE: {mae}\")\n",
    "    print(f\"  MAPE: {mape}\")\n",
    "    print(f\"  Kernel: {kernel}\")\n",
    "    print(\"  Parameters:\")\n",
    "    for param_name, param_value in params.items():\n",
    "        print(f\"    {param_name}: {param_value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e876ee7-28ba-4c3a-a0be-6ebbad4d8f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the best kernel and the corresponding scalar value\n",
    "best_kernel = results[0][3]\n",
    "best_params = results[0][4]\n",
    "\n",
    "# Set the best parameters to the best kernel\n",
    "for param, value in best_params.items():\n",
    "    setattr(best_kernel, param, value)\n",
    "\n",
    "# Train a Gaussian Process Regressor with the best kernel\n",
    "gp_best_combined = GaussianProcessRegressor(kernel=best_kernel, n_restarts_optimizer=10)\n",
    "gp_best_combined.fit(X, y)\n",
    "\n",
    "# Make predictions for the entire dataset using the best combined kernel\n",
    "y_mean_combined, y_cov_combined = gp_best_combined.predict(X, return_cov=True)\n",
    "\n",
    "# Define the number of years to forecast\n",
    "num_years_forecast = 13\n",
    "\n",
    "# Extend the range of x_NHM to cover the forecast period\n",
    "x_forecast = np.arange(X.min(), X.max() + num_years_forecast + 1).reshape(-1, 1)\n",
    "\n",
    "# Make predictions for the forecast period using the best combined kernel\n",
    "y_mean_forecast_combined, y_cov_forecast_combined = gp_best_combined.predict(x_forecast, return_cov=True)\n",
    "\n",
    "# Plot the observed data, predicted mean with the best combined kernel, and forecast\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X, y, c='b', label='Observed Data')\n",
    "# plt.plot(X, y_mean_combined, 'k', lw=2, zorder=9, label='Predicted Mean (Best Kernel)')\n",
    "# plt.fill_between(X[:, 0], y_mean_combined - 1.96 * np.sqrt(np.diag(y_cov_combined)),\n",
    "#                  y_mean_combined + 1.96 * np.sqrt(np.diag(y_cov_combined)), alpha=0.8, color='blue', label='95% Confidence Interval')\n",
    "\n",
    "plt.plot(x_forecast, y_mean_forecast_combined, '--', color='green', label='Forecast')\n",
    "plt.fill_between(x_forecast[:, 0], y_mean_forecast_combined - 1.96 * np.sqrt(np.diag(y_cov_forecast_combined)),\n",
    "                 y_mean_forecast_combined + 1.96 * np.sqrt(np.diag(y_cov_forecast_combined)), alpha=0.2, color='green', label='95% Confidence Interval (Forecast)')\n",
    "\n",
    "plt.xlabel('Year', fontsize=16)  # Adjust fontsize as needed\n",
    "plt.ylabel('VMT (billion miles)', fontsize=16)  # Adjust fontsize as needed\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)  # Adjust fontsize as needed for major ticks\n",
    "plt.legend(loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig('../../../figures/forecast-vmt-newhaven——dot.png', dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bbe8cb6-36f8-4baa-8c4e-4f7b55575937",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../data/raw/mv1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_vehicle_re \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../data/raw/mv1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m statewide_vehicle \u001b[38;5;241m=\u001b[39m df_vehicle_re\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m14\u001b[39m, :]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# the total number of each vehicle type\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../data/raw/mv1.csv'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "df_vehicle_re = pd.read_csv('../../../data/raw/mv1.csv')\n",
    "\n",
    "statewide_vehicle = df_vehicle_re.iloc[14, :]\n",
    "\n",
    "# the total number of each vehicle type\n",
    "statewide_automobile = statewide_vehicle.iloc[3]\n",
    "statewide_buses = statewide_vehicle.iloc[6]\n",
    "statewide_trucks = statewide_vehicle.iloc[9]\n",
    "statewide_motorcycle = statewide_vehicle.iloc[12]\n",
    "statewide_total = statewide_vehicle.iloc[15]\n",
    "\n",
    "# ratio of each vehicle type to the total\n",
    "statewide_automobile = int(str(statewide_automobile).translate(str.maketrans('', '', string.punctuation)))\n",
    "statewide_buses = int(str(statewide_buses).translate(str.maketrans('', '', string.punctuation)))\n",
    "statewide_trucks = int(str(statewide_trucks).translate(str.maketrans('', '', string.punctuation)))\n",
    "statewide_motorcycle = int(str(statewide_motorcycle).translate(str.maketrans('', '', string.punctuation)))\n",
    "statewide_total = int(str(statewide_total).translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "automobile_rat = statewide_automobile / statewide_total\n",
    "buses_rat = statewide_buses / statewide_total\n",
    "trucks_rat = statewide_trucks / statewide_total\n",
    "motorcycle_rat = statewide_motorcycle / statewide_total\n",
    "\n",
    "statewide_vehicle = statewide_vehicle.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb805b-331b-4a0c-a000-98519e64929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emissions(VMT):\n",
    "    automobile_vmt=VMT*automobile_rat\n",
    "    buses_vmt=VMT*buses_rat\n",
    "    trucks_vmt=VMT*trucks_rat\n",
    "    motorcycle_vmt=VMT*motorcycle_rat\n",
    "\n",
    "    #average MPG for each vehicle type ( miles per gallons)\n",
    "    passenger_car_gasoline=24.1#automobile\n",
    "    passenger_car_diesel=32.4\n",
    "    light_truck_gasoline=18.5\n",
    "    light_truck_diesel=22.1#trucks\n",
    "    heavy_duty_gasoline=10.13\n",
    "    heavy_duty_diesel=12.96#buses\n",
    "    motorcycle_gasoline=50#motorcycle\n",
    "\n",
    "    #emission factor for different fuels (kg CO2/gallon)( referenced from the ghg tool community module)\n",
    "    gasoline=8.78\n",
    "    diesel=10.21\n",
    "\n",
    "    #calculate the fuel consumption in NH MSA\n",
    "    gaso_consump= automobile_vmt/passenger_car_gasoline+motorcycle_vmt/motorcycle_gasoline\n",
    "    dies_consump= buses_vmt/heavy_duty_diesel+trucks_vmt/light_truck_diesel\n",
    "\n",
    "    #calcualte the gasoline and diesel emissions: carbon dioxide emissions only\n",
    "    gaso_emissions =gaso_consump*gasoline/1000\n",
    "    dies_emissions =dies_consump*diesel/1000\n",
    "\n",
    "    #calculate the carbon dioxide consumption(metric tons):\n",
    "    CO2=gaso_consump*gasoline/1000+dies_consump*diesel/1000\n",
    "\n",
    "    gaso_auto=automobile_vmt/passenger_car_gasoline\n",
    "    gaso_motor=motorcycle_vmt/motorcycle_gasoline\n",
    "    die_trucks=trucks_vmt/light_truck_diesel\n",
    "    die_buses=buses_vmt/heavy_duty_diesel\n",
    "\n",
    "    #emission factor for different vehicles : g/miles ( referenced from EPA emission hub)\n",
    "    # based on year 2005\n",
    "    CH4_gaso_passenger_car=0.008\n",
    "    N2O_gaso_passenger_car=0.007\n",
    "\n",
    "    CH4_gaso_motorcycle=0\n",
    "    N2O_gaso_motorcycle=0\n",
    "\n",
    "    CH4_buses=0.005\n",
    "    N2O_buses=0.005 #( meidum- heavy-duty vehicles in year 2005)\n",
    "\n",
    "    CH4_trucks=0.001 #( light-duty trucks)\n",
    "    N2O_trucks=0.001\n",
    "\n",
    "    #calculate the CH4 emission (metric tons):\n",
    "    CH4=automobile_vmt*CH4_gaso_passenger_car/1000000+motorcycle_vmt*CH4_gaso_motorcycle/1000000+buses_vmt*CH4_buses/1000000+trucks_vmt*CH4_trucks/1000000\n",
    "\n",
    "    #convert to carbon dioxide equavelence:\n",
    "    CO2_equ_1=CH4*25\n",
    "\n",
    "    #calculate the N2O emission (metric tons):\n",
    "    N2O = automobile_vmt*N2O_gaso_passenger_car/1000000 + motorcycle_vmt*N2O_gaso_motorcycle/1000000+buses_vmt*N2O_buses/1000000+trucks_vmt*N2O_trucks/1000000\n",
    "\n",
    "    #convert to carbon dioxide equavelence:\n",
    "    CO2_equ_2=N2O*298#define the number \n",
    "\n",
    "    #calculation of emissions from each types of vehicle,MMTCO2e(autombile, motorcycle, trucks, buses-NH,HH,BSN)\n",
    "    automobile = (automobile_vmt/passenger_car_gasoline*gasoline/1000+automobile_vmt*CH4_gaso_passenger_car/1000000*25+automobile_vmt*N2O_gaso_passenger_car/1000000*298)*1000\n",
    "    motorcycle = (motorcycle_vmt/motorcycle_gasoline*gasoline/1000+motorcycle_vmt*CH4_gaso_motorcycle/1000000*25+motorcycle_vmt*N2O_gaso_motorcycle/1000000*298)*1000\n",
    "    buses = (buses_vmt/heavy_duty_diesel*diesel/1000+buses_vmt*CH4_buses/1000000*25+buses_vmt*N2O_buses/1000000*298)*1000\n",
    "    trucks = (trucks_vmt/light_truck_diesel*diesel/1000+trucks_vmt*CH4_trucks/1000000*25+trucks_vmt*N2O_trucks/1000000*298)*1000\n",
    "\n",
    "    total = automobile+motorcycle+buses+trucks\n",
    "    \n",
    "    return total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
